'use server';
/**
 * generate-response-with-tools.ts
 *
 * Adds a simple MCP-style tool loop to your existing generateResponse flow.
 * - Tools: mathEvaluator, todoTool (uses Firestore via firebase-admin)
 * - The model may return a `toolRequest`. When that happens, the agent executes
 *   the named tool, supplies `toolResponse` back to the model, and asks the model
 *   to finalize or call another tool.
 *
 * Usage: call `generateResponse(input)` the same way you called the previous flow.
 */

import { ai } from '@/ai/genkit';
import { z } from 'genkit';
import * as admin from 'firebase-admin';

// Initialize firebase-admin (safe to call multiple times)
if (!admin.apps.length) {
  try {
    admin.initializeApp();
  } catch (e) {
    // ignore double init in non-cloud-run environments
  }
}
const db = admin.firestore();

// -----------------------------
// Tool Definitions
// -----------------------------

const mathEvaluator = ai.defineTool(
  {
    name: 'mathEvaluator',
    description: 'Evaluates a simple mathematical expression. (demo only; eval used for speed)',
    inputSchema: z.object({
      expression: z.string().describe('A simple JS math expression like "2+2*3"'),
    }),
    outputSchema: z.any(),
  },
  async (input) => {
    try {
      // WARNING: eval() is unsafe for arbitrary input. This is a dev-only tool.
      // Replace with a proper math parser (mathjs) in prod.
      const result = eval(input.expression);
      return { result: String(result) };
    } catch (err: any) {
      return { error: `Error evaluating expression: ${err?.message ?? String(err)}` };
    }
  }
);

const todoTool = ai.defineTool(
  {
    name: 'todoTool',
    description:
      'Simple Firestore-backed todo tool. Actions: add, list, complete. Uses sessionId to namespace todos.',
    inputSchema: z.object({
      action: z
        .enum(['add', 'list', 'complete'])
        .describe('Action to perform on todos'),
      sessionId: z.string().optional().describe('Optional sessionId to scope todos'),
      text: z.string().optional().describe('Text for add action'),
      id: z.string().optional().describe('ID for complete action'),
    }),
    outputSchema: z.any(),
  },
  async (input) => {
    const collectionBase = 'tool_memory/todoTool/items';
    try {
      if (input.action === 'add') {
        if (!input.text) return { error: 'Missing text for add action' };
        const docRef = await db.collection(collectionBase).add({
          text: input.text,
          completed: false,
          sessionId: input.sessionId || null,
          createdAt: admin.firestore.FieldValue.serverTimestamp(),
        });
        return { ok: true, id: docRef.id, text: input.text };
      }

      if (input.action === 'list') {
        let q = db.collection(collectionBase).orderBy('createdAt', 'desc').limit(200);
        if (input.sessionId) q = q.where('sessionId', '==', input.sessionId);
        const snap = await q.get();
        const items = snap.docs.map((d) => ({ id: d.id, ...(d.data() as any) }));
        return { items };
      }

      if (input.action === 'complete') {
        if (!input.id) return { error: 'Missing id for complete action' };
        const ref = db.collection(collectionBase).doc(input.id);
        await ref.update({ completed: true });
        return { ok: true, id: input.id };
      }

      return { error: 'Unknown action' };
    } catch (err: any) {
      return { error: err?.message ?? String(err) };
    }
  }
);

// Tool registry for runtime execution
const TOOL_REGISTRY: Record<string, any> = {
  mathEvaluator,
  todoTool,
};

// -----------------------------
// Schemas (extended for tool requests/responses)
// -----------------------------

const ToolRequestSchema = z.object({
  name: z.string().describe('Tool name to call'),
  input: z.any().optional().describe('Tool input payload'),
});

const ToolResponseSchema = z.any();

const GenerateResponseInputSchema = z.object({
  userMessage: z.string().describe('The user message to be processed.'),
  memory: z.array(z.string()).describe('A list of facts the agent has remembered from the conversation.'),
  // Optional incoming toolResponse from previous tool execution loop
  toolResponse: z.any().optional().describe('Optional result from a tool run (for tool loops)'),
});

export type GenerateResponseInput = z.infer<typeof GenerateResponseInputSchema>;

const GenerateResponseOutputSchema = z.object({
  response: z.string().describe('The response generated by the model.'),
  reasoning: z.string().describe('The step-by-step reasoning process of the model.'),
  newFacts: z.array(z.string()).describe('New facts to save to memory.'),
  // Optional suggested tool request (model asks the runtime to run a tool)
  toolRequest: ToolRequestSchema.optional(),
  // Optional tool response included when model returns it in structured output
  toolResponse: ToolResponseSchema.optional(),
});

export type GenerateResponseOutput = z.infer<typeof GenerateResponseOutputSchema>;

// -----------------------------
// Prompt
// -----------------------------

const generateResponsePrompt = ai.definePrompt({
  name: 'generateResponseWithToolsPrompt',
  input: { schema: GenerateResponseInputSchema },
  output: { schema: GenerateResponseOutputSchema },
  prompt: `You are a helpful assistant with memory and access to tools.

You are given:
- A list of memory facts (use them if relevant).
- The user's message.
- Optionally, the result of a previously-run tool in 'toolResponse'.

Your goals:
1. Answer the user's message directly and conversationally.
2. If you *need* external actions or data (math, todo operations), request a tool by returning a structured object in 'toolRequest', e.g.:
   { "toolRequest": { "name": "mathEvaluator", "input": { "expression": "2+2" } } }
   OR
   { "toolRequest": { "name": "todoTool", "input": { "action": "add", "text": "buy milk", "sessionId": "s1" } } }

   If you request a tool, **do not** also provide the final user-facing response yet — instead the runtime will run the tool and return its result to you as \`toolResponse\`. After receiving \`toolResponse\`, call the prompt again and finalize the response.

3. Provide \`reasoning\` (brief) explaining how you answered or why you requested the tool.
4. Return \`newFacts\` — small facts to save to memory (or []).

Remember:
- If \`toolResponse\` is present, incorporate it into your reasoning and provide a final user-facing \`response\`.
- Keep \`toolRequest\` and \`toolResponse\` strictly JSON-serializable (no functions).
- Only request tools when necessary.

Current Memory/Facts:
{{#if memory}}
{{#each memory}}
- {{{this}}}
{{/each}}
{{else}}
- Memory is empty.
{{/if}}

User message:
{{{userMessage}}}

Previous tool result (if any):
{{#if toolResponse}}
{{{toolResponse}}}
{{else}}
- none
{{/if}}
`,
});

// -----------------------------
// Flow (implements tool loop)
// -----------------------------

export async function generateResponse(
  input: GenerateResponseInput
): Promise<GenerateResponseOutput> {
  return generateResponseFlow(input);
}

const MAX_TOOL_LOOPS = 3;

const generateResponseFlow = ai.defineFlow(
  {
    name: 'generateResponseWithToolsFlow',
    inputSchema: GenerateResponseInputSchema,
    outputSchema: GenerateResponseOutputSchema,
  },
  async (input) => {
    // local copy we will update with toolResponse when available
    let promptInput: any = { ...input };

    let lastOutput: GenerateResponseOutput | null = null;

    for (let loop = 0; loop < MAX_TOOL_LOOPS; loop++) {
      const { output } = await generateResponsePrompt(promptInput);
      if (!output) throw new Error('No output from model');

      // model's structured output
      const modelOut = output as GenerateResponseOutput;
      lastOutput = modelOut;

      // If the model requested a tool, execute it and feed the result back
      if (modelOut.toolRequest && modelOut.toolRequest.name) {
        const tr = modelOut.toolRequest;
        const tool = TOOL_REGISTRY[tr.name];
        if (!tool) {
          // If requested unknown tool, return an error-like response
          return {
            response: `I can't run the tool "${tr.name}".`,
            reasoning: `Requested unknown tool: ${tr.name}`,
            newFacts: [],
          };
        }

        let toolResult: any;
        try {
          // The 'tool' variable is the actual awaitable tool function defined with `ai.defineTool`.
          // We can call it directly with the input provided by the model.
          toolResult = await tool(tr.input ?? {});
        } catch (err: any) {
          toolResult = { error: err?.message ?? String(err) };
        }

        // Put the tool result back into the prompt and loop
        promptInput = {
          ...promptInput,
          toolResponse: toolResult,
        };

        // continue the loop to allow the model to finalize after seeing toolResponse
        continue;
      }

      // No tool requested — we have a final response
      return {
        response: modelOut.response,
        reasoning: modelOut.reasoning,
        newFacts: modelOut.newFacts || [],
        // ensure no dangling toolRequest/toolResponse in return schema
      } as GenerateResponseOutput;
    }

    // Max loop reached — return last output (if present)
    if (lastOutput) {
      return {
        response: lastOutput.response || 'Sorry — could not finish tool loop.',
        reasoning: lastOutput.reasoning || 'Max tool loops reached.',
        newFacts: lastOutput.newFacts || [],
      };
    }

    // Shouldn't happen, but safe fallback
    return {
      response: 'No output from model.',
      reasoning: 'No output after running the prompt.',
      newFacts: [],
    };
  }
);
